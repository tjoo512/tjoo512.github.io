<!DOCTYPE HTML>
<html lang="en">

<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-BQVL6PCVM7"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-BQVL6PCVM7');
  </script>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Taejong Joo</title>
  <meta name="author" content="Taejong Joo">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <div class="container">
    <!-- Header Section -->
    <div class="profile">
      <div class="profile-text">
        <h1 class="name">Taejong Joo</h1>
        <p>
          I am a fourth-year PhD student in the <a href="https://www.mccormick.northwestern.edu/industrial/">Department
            of Industrial Engineering & Management Sciences</a> at <a href="https://www.northwestern.edu/">Northwestern
            University</a>, where I am fortunate to work with <a href="https://dynresmanagement.com/index.html">Diego
            Klabjan</a>.
          My research focuses on robust machine learning, uncertainty estimation, foundation models, and AI alignment.
        </p>
        <p>
          My aspiration is to develop AI systems with human-level adaptability and computational properties aligned with
          human preferences.
          Such AI systems would enable effective collaboration between humans and machines to tackle evolving real-world
          challenges that neither could solve alone.
        </p>
        <p>
          Previously, I was a senior deep learning researcher at <a href="https://estsoft.ai/en/">ESTsoft</a>, where I
          worked on distribution shifts, contextual bandit, scalable variational inference, and model compression.
          I built the company's first ML model, which had been successfully operated in the Korean stock market.
        </p>
        <p>
          Before that, I obtained my bachelor’s and master’s degrees at <a
            href="https://www.hanyang.ac.kr/web/eng">Hanyang University</a>, where I worked on human-machine
          interactions. My research on formalizing human-machine interactions for safe and efficient manufacturing
          systems was featured among the top 50 most popular articles in <em>IEEE Transactions on Human-Machine
            Systems</em>.
        </p>
        <p>
          <em>
            I am actively seeking research roles, including internships and full-time positions. With work eligibility
            in the U.S. and Germany, I am open to relocation and eager to explore diverse domains. While I value
            publication opportunities, my main goal is to work on pressing challenges with high impact. I thrive in
            technically and culturally diverse teams and am eager to contribute my skills and perspectives. Thank you
            for your consideration!
          </em>
        </p>
        <p>
          For any inquiries, please feel free to contact me by email: taejong.joo [at] northwestern.edu
        </p>
      </div>
      <div class="profile-image">
        <a href="images/profile.jpg">
          <img src="images/profile.jpg" alt="profile photo">
        </a>
      </div>
    </div>

    <!-- Research Section -->
    <div class="section">
      <h2>Selected Research</h2>
      <p>For the full list of my publications, visit my <a
          href="https://scholar.google.com/citations?user=ESo1UqMAAAAJ&hl=en">Google Scholar</a>.</p>
      <br>

      <div class="research-item">
        <img src="images/ancon.png" alt="Research Image">
        <div>
          <a href="https://arxiv.org/abs/2411.00586" class="papertitle">Improving Self-Training Under Distribution
            Shifts via Anchored Confidence With Theoretical Guarantees</a>
          <strong>Taejong Joo, Diego Klabjan</strong><br>
          <em>Neural Information Processing Systems (NeurIPS)</em>, 2024
          <br><br>
          <p>
            &thinsp; We prove that selectively promoting temporal consistency for confident predictions significantly
            enhances self-training performance under distribution shifts. This approach prevents the common issue of
            model collapse—where performance deteriorates after a few epochs of self-training—resulting in improved
            performances with attractive robustness properties.
          </p>
        </div>
      </div>

      <div class="research-item">
        <img src="images/iw_gae.png" alt="Research Image">
        <div>
          <a href="https://arxiv.org/abs/2310.10611" class="papertitle">IW-GAE: Importance Weighted Group Accuracy
            Estimation for Improved Calibration and Model Selection in Unsupervised Domain Adaptation</a>
          <strong>Taejong Joo, Diego Klabjan</strong><br>
          <em>International Conference on Machine Learning (ICML)</em>, 2024
          <br><br>
          <p>
            &thinsp; We introduce a new approach for simultaneously addressing model calibration and model selection in
            unsupervised domain adaptation: estimating the average accuracy across subpopulations. For efficient and
            accurate subpopulation accuracy estimation, we formulate the high-dimensional importance weight estimation
            problem into a more tractable coordinate-wise convex optimization problem.
          </p>
        </div>
      </div>

      <div class="research-item">
        <img src="images/bm.png" alt="Research Image">
        <div>
          <a href="https://proceedings.mlr.press/v119/joo20a.html" class="papertitle">Being Bayesian about Categorical
            Probability</a>
          <strong>Taejong Joo, Uijung Chung, Min-Gwan Seo</strong><br>
          <em>International Conference on Machine Learning (ICML)</em>, 2020
          <br><br>
          <p>
            &thinsp; We propose a scalable variational inference framework using a last-layer Dirichlet model as a new
            alternative to Bayesian neural networks. Our approach significantly enhances uncertainty representation
            ability of deterministic neural networks while preserving their strong generalization performances and
            efficiency unlike Monte Carlo dropout and deep ensembles.
          </p>
        </div>
      </div>
    </div>


    <!-- Miscellaneous Section -->
    <div class="section">
      <h2>Misc.</h2>
      <p>
        Guided by first principles and the elegance of Occam’s razor, I believe simplicity often reveals the deepest
        insights and leads to effective and versatile solutions (with far fewer headaches).
      </p>
      <p>
        Outside of work, I enjoy experimenting in the kitchen as a self-proclaimed master chef (enthusiastically
        endorsed by my wife), playing tennis, splashing paint on canvas, and traveling.
      </p>
      <p>
        Fun fact: My Erdős Number = 3: Taejong Joo -> Diego Klabjan -> Craig Tovey -> Paul Erdős.
      </p>
    </div>

    <!-- Footer Section -->
    <footer>
      <p>Template by <a href="http://jonbarron.info/">Jon Barron</a> (<a
          href="https://github.com/jonbarron/jonbarron_website">source code</a>).</p>
    </footer>
  </div>
</body>

</html>
