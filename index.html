<!DOCTYPE HTML>
<html lang="en">

<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-BQVL6PCVM7"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-BQVL6PCVM7');
  </script>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Taejong Joo</title>
  <meta name="author" content="Taejong Joo">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <div class="container">
    <!-- Header Section -->
    <div class="profile">
      <div class="profile-text">
        <h1 class="name">Taejong Joo</h1>
        <p>
          I am a final-year PhD student in the <a href="https://www.mccormick.northwestern.edu/industrial/">Department
            of Industrial Engineering & Management Sciences</a> at <a href="https://www.northwestern.edu/">Northwestern
            University</a>, where I am fortunate to work with <a href="https://dynresmanagement.com/index.html">Diego
            Klabjan</a>.
        </p><p>
            My aspiration is to develop AI systems with human-level adaptability and computational properties aligned with human preferences.
             Such AI systems would enable effective collaboration between humans and machines to tackle evolving real-world challenges that
              neither could solve alone. With this ambition, I’m currently working on post-training large language models, model adaptation, and robust machine learning.
        </p>
        <p>
          Previously, I obtained my bachelor’s and master’s degrees at <a
            href="https://www.hanyang.ac.kr/web/eng">Hanyang University</a>, where I worked on human-machine
          interactions. My research on formalizing human-machine interactions to enable adaptive automation under 
           safety constraints was featured among the top 50 most popular articles in <em>IEEE Transactions on Human-Machine
            Systems</em>.
        </p>
        <br>
        <p>
          <em>
            I’m seeking research scientist or postdoctoral roles in leading research labs tackling high-impact challenges.
             I thrive in technically and culturally diverse teams and am eager to contribute my skills and perspective to pioneering
              foundational advances in AI. I am open to relocation, with a preference for the Bay Area, NYC, Berlin, Zurich, London, or Paris.
          </em>
        </p>
        <p>Email: taejong.joo [at] northwestern.edu</p>
      </div>
      <div class="profile-image">
        <a href="images/profile.jpg">
          <img src="images/profile.jpg" alt="profile photo">
        </a>
      </div>
    </div>

    <!-- Experience Section -->
    <div class="section">
      <h2>Industrial Experience</h2><br>
      <div class="company-item">
        <img src="images/google_logo.png">
        <div>
          <strong>Google</strong><br>
          2025.03~2025.06 / 2025.09~2025.10<br>
          Student Researcher <br>
          <p class="small-space">
            &thinsp;  Memory-efficient optimizers for (pre-/post-) training large-language models.
          </p>
        </div>
      </div>

      <div class="company-item">
        <img src="images/autodesk_logo.jpg">
        <div>
          <strong>Autodesk Research</strong><br>
          2025.06~ 2025.09<br>
          Research Intern <br>
          <p class="small-space">
            &thinsp; Multi-agent system for long context modeling.
          </p>
        </div>
      </div>


      <div class="company-item">
        <img src="images/ESTsoft_Logo.png">
        <div>
          <strong>ESTsoft</strong><br>
          2018.01 ~ 2021.05 <br>
          Deep Learning Researcher (Senior from 2021.01) <br>
          <p class="small-space">
            &thinsp;  Offline reinforcement learning for financial portfolio optimization, scalable variational inference for uncertainty estimation, distribution shifts, and model compression. 
          </p>
        </div>
      </div>

    <!-- Research Section -->
    <div class="section">
      <h2>Selected Research</h2>
      <p>For the full list of my publications, visit my <a
          href="https://scholar.google.com/citations?user=ESo1UqMAAAAJ&hl=en">Google Scholar</a>.</p>
      <br>

      <div class="research-item">
        <img src="images/goa.png" alt="Research Image">
        <div>
          <a href="https://arxiv.org/abs/2509.21848" class="papertitle">Graph of Agents: Principled Long Context Modeling by
             Emergent Multi-Agent Collaboration</a>
          <strong>Taejong Joo, Shu Ishida, Ivan Sosnovik, Bryan Lim, Sahand Rezaei-Shoshtari, Adam Gaier, Robert Giaquinto</strong><br>
          Preprint, 2025
          <br><br>
          <p>
            &thinsp;  We develop Graph of Agents, a multi-agent system that expands the context window of large language
             models by orders of magnitude without any additional training. By framing long context modeling as a
              compression problem, GoA dynamically builds an optimal multi-agent collaboration structure tailored to
               the input. This principled approach eliminates the need for complex prompt engineering and specialized
                multi-agent system designs. 
          </p>
        </div>
      </div>

      <div class="research-item">
        <img src="images/icl_tech_debt.png" alt="Research Image">
        <div>
          <a href="https://arxiv.org/abs/2502.04580" class="papertitle">Technical Debt in In-Context Learning:
             Diminishing Efficiency in Long Context</a>
          <strong>Taejong Joo, Diego Klabjan</strong><br>
          <em>Neural Information Processing Systems (NeurIPS)</em>, 2025
          <br><br>
          <p>
            &thinsp;  We demonstrate that the convenience of in-context learning, which enables adaptation to a new
             task by conditioning on demonstrations in an input prompt, comes with a hidden cost. While it matches
              the efficiency of a Bayes-optimal estimator in few-shot settings, we prove its statistical efficiency
               fundamentally diminishes over long contexts. This reveals a critical trade-off between ICL's flexibility
                and its long-term statistical efficiency.
          </p>
        </div>
      </div>


      <div class="research-item">
        <img src="images/ancon.png" alt="Research Image">
        <div>
          <a href="https://arxiv.org/abs/2411.00586" class="papertitle">Improving Self-Training Under Distribution
            Shifts via Anchored Confidence With Theoretical Guarantees</a>
          <strong>Taejong Joo, Diego Klabjan</strong><br>
          <em>Neural Information Processing Systems (NeurIPS)</em>, 2024
          <br><br>
          <p>
            &thinsp; We prove that selectively promoting temporal consistency for confident predictions significantly
            enhances self-training performance under distribution shifts. This approach prevents the common issue of
            model collapse—where performance deteriorates after a few epochs of self-training—resulting in improved
            performances with attractive robustness properties.
          </p>
        </div>
      </div>

      <div class="research-item">
        <img src="images/iw_gae.png" alt="Research Image">
        <div>
          <a href="https://arxiv.org/abs/2310.10611" class="papertitle">IW-GAE: Importance Weighted Group Accuracy
            Estimation for Improved Calibration and Model Selection in Unsupervised Domain Adaptation</a>
          <strong>Taejong Joo, Diego Klabjan</strong><br>
          <em>International Conference on Machine Learning (ICML)</em>, 2024
          <br><br>
          <p>
            &thinsp; We introduce a new approach for simultaneously addressing model calibration and model selection in
            unsupervised domain adaptation: estimating the average accuracy across subpopulations. For efficient and
            accurate subpopulation accuracy estimation, we formulate the high-dimensional importance weight estimation
            problem into a more tractable coordinate-wise convex optimization problem.
          </p>
        </div>
      </div>

      <div class="research-item">
        <img src="images/bm.png" alt="Research Image">
        <div>
          <a href="https://proceedings.mlr.press/v119/joo20a.html" class="papertitle">Being Bayesian about Categorical
            Probability</a>
          <strong>Taejong Joo, Uijung Chung, Min-Gwan Seo</strong><br>
          <em>International Conference on Machine Learning (ICML)</em>, 2020
          <br><br>
          <p>
            &thinsp; We propose a scalable variational inference framework using a last-layer Dirichlet model as a new
            alternative to Bayesian neural networks. Our approach significantly enhances uncertainty representation
            ability of deterministic neural networks while preserving their strong generalization performances and
            efficiency unlike Monte Carlo dropout and deep ensembles.
          </p>
        </div>
      </div>
    </div>


    <!-- Miscellaneous Section -->
    <div class="section">
      <h2>Misc.</h2>
      <p>
        Guided by first principles and the elegance of Occam’s razor, I believe simplicity often reveals the deepest
        insights and leads to effective and versatile solutions (with far fewer headaches).
      </p>
      <p>
        Outside of work, I enjoy experimenting in the kitchen as a self-proclaimed master chef (enthusiastically
        endorsed by my wife), playing tennis, splashing paint on canvas, and traveling.
      </p>
      <p>
        Fun fact: My Erdős Number = 3: Taejong Joo -> Diego Klabjan -> Craig Tovey -> Paul Erdős.
      </p>
    </div>

    <!-- Footer Section -->
    <footer>
      <p>Template by <a href="http://jonbarron.info/">Jon Barron</a> (<a
          href="https://github.com/jonbarron/jonbarron_website">source code</a>).</p>
    </footer>
  </div>
</body>

</html>
